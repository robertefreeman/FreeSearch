# =============================================================================
# FreeSearch Legal Research Agent Configuration
# =============================================================================
# Copy this file to .env and uncomment/configure the variables you need.
# All variables are optional - the system will use defaults if not specified.

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Choose your LLM provider: "gemini" (default) or "openai"
# LLM_PROVIDER=gemini

# =============================================================================
# Google Gemini Configuration (Default Provider)
# =============================================================================
# Google Gemini API key - required if using Gemini provider
# GEMINI_API_KEY=

# =============================================================================
# OpenAI Configuration (OpenAI and OpenAI-Compatible Providers)
# =============================================================================
# Required for OpenAI provider
# LLM_PROVIDER=openai
# OPENAI_API_KEY=

# API base URL for OpenAI-compatible providers
# For OpenAI: https://api.openai.com/v1 (default)
# For Ollama: http://localhost:11434/v1
# For Together AI: https://api.together.xyz/v1
# For other providers: customize as needed
# OPENAI_API_BASE=https://api.openai.com/v1

# =============================================================================
# Model Configuration
# =============================================================================
# Model names for different agent functions
# Default values are shown - customize based on your provider

# Query Generator Model (generates legal search queries)
# Gemini default: gemini-2.0-flash
# OpenAI example: gpt-4o-mini
# Ollama example: llama3.2
# QUERY_GENERATOR_MODEL=

# Reflection Model (analyzes research gaps)
# Gemini default: gemini-2.5-flash-preview-04-17
# OpenAI example: gpt-4o
# Ollama example: llama3.2
# REFLECTION_MODEL=

# Answer Model (generates final legal analysis)
# Gemini default: gemini-2.5-pro-preview-05-06
# OpenAI example: gpt-4o
# Ollama example: llama3.2
# ANSWER_MODEL=

# =============================================================================
# Research Configuration
# =============================================================================
# Number of initial search queries to generate (default: 3)
# NUMBER_OF_INITIAL_QUERIES=3

# Maximum number of research loops to perform (default: 2)
# MAX_RESEARCH_LOOPS=2

# =============================================================================
# Example Configurations
# =============================================================================

# Example 1: Google Gemini (Default)
# GEMINI_API_KEY=your_gemini_api_key_here

# Example 2: OpenAI
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_API_BASE=https://api.openai.com/v1
# QUERY_GENERATOR_MODEL=gpt-4o-mini
# REFLECTION_MODEL=gpt-4o
# ANSWER_MODEL=gpt-4o

# Example 3: Ollama (Local)
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_key_here
# OPENAI_API_BASE=http://localhost:11434/v1
# QUERY_GENERATOR_MODEL=llama3.2
# REFLECTION_MODEL=llama3.2
# ANSWER_MODEL=llama3.2

# Example 4: Together AI
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_together_api_key_here
# OPENAI_API_BASE=https://api.together.xyz/v1
# QUERY_GENERATOR_MODEL=meta-llama/Llama-3.2-3B-Instruct-Turbo
# REFLECTION_MODEL=meta-llama/Llama-3.2-3B-Instruct-Turbo
# ANSWER_MODEL=meta-llama/Llama-3.2-3B-Instruct-Turbo